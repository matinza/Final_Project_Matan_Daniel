{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f7e1c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "# from lib2to3.pgen2 import driver\n",
    "from IPython.display import Javascript\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import itertools as it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ed249f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<center><h1><b>MarkUp</b></h1></center>\n",
    "\n",
    "---\n",
    "\n",
    "- After creating the \"Udemy_URLS\" csv file using crawling, we extracted the diffrent urls from the file and using selenium and Beautiful soup(we needed the selelnium because of the problem of \"dynamic Javascript\") created a loop which in every iteration we pulled URL, appended https and started the driver with this url and got the html with all the elements.\n",
    "- After we got the html content we started extracting the elements information like: best_seller, course_rating_avarage, course_price, and etc...\n",
    "- If the website failed to rise then we move forward to the next url\n",
    "- If any of the elemets failed during extaraction we saved -1 instead\n",
    "- In the end, we saved all the inforamtion to the CSV file called 'UDEMY_DATA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649579d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "global urls\n",
    "urls = pd.read_csv('./Udemy_URLS.csv')\n",
    "global url\n",
    "url = ''\n",
    "global start_index\n",
    "start_index = 26008\n",
    "global end_index\n",
    "end_index = 26009\n",
    "\n",
    "def forward_url():\n",
    "    global url\n",
    "    global start_index\n",
    "    global end_index\n",
    "    \n",
    "    start_index = start_index + 1\n",
    "    end_index = end_index + 1\n",
    "    with open('./Udemy_URLS.csv') as f:\n",
    "        reader=csv.reader(f)\n",
    "        url = 'https://' + next(it.islice(reader, start_index, end_index))[0]\n",
    "    run_web_driver()\n",
    "    \n",
    "def run_web_driver():\n",
    "    global url\n",
    "    try:\n",
    "        opts = Options()\n",
    "        os.environ['WDM_LOG_LEVEL'] = '0'\n",
    "        opts.add_argument(\"start-maximized\")\n",
    "        opts.add_experimental_option('excludeSwitches', ['enable-logging'])\n",
    "        opts.add_argument(\"start-maximized\")\n",
    "        opts.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "        opts.add_experimental_option('excludeSwitches', ['enable-logging'])\n",
    "        opts.add_experimental_option('useAutomationExtension', False)\n",
    "        opts.add_argument('--disable-blink-features=AutomationControlled')\n",
    "#         opts.add_argument('--headless')\n",
    "        opts.add_argument('--disable-gpu')  # Last I checked this was necessary.\n",
    "#         opts.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36\")\n",
    "#         opts.add_argument(\"user-agent=\" + agent)\n",
    "        driver = webdriver.Chrome(chrome_options = opts)\n",
    "        driver.maximize_window()\n",
    "        time.sleep(8)\n",
    "        driver.get(url)\n",
    "        time.sleep(10)\n",
    "        \n",
    "        soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "        driver.close()\n",
    "        \n",
    "        #best_seller\n",
    "        best_seller = -1\n",
    "        try:  \n",
    "            best_seller_text = ''\n",
    "            for a in soup.select('div.clp-lead__badge-ratings-enrollment'):\n",
    "                for b in soup.select('div.clp-lead__element-item'):\n",
    "                    best_seller_text = b.text\n",
    "                    break\n",
    "                \n",
    "                if(best_seller_text == 'Bestseller'):\n",
    "                    best_seller = 1\n",
    "                else:\n",
    "                    best_seller = 0\n",
    "                    break\n",
    "#             print(best_seller)\n",
    "        except Exception as e: \n",
    "            best_seller = -1\n",
    "#             print(\"best seller fail: \")#+ str(e))\n",
    "            \n",
    "        \n",
    "        #course_rating_avarage\n",
    "        course_rating_avarage = -1\n",
    "        try:\n",
    "            course_rating_avarage_elem = soup.find('span', {\"class\" : 'udlite-heading-sm star-rating--rating-number--2o8YM'})\n",
    "            course_rating_avarage = course_rating_avarage_elem.string\n",
    "#             print(course_rating_avarage)\n",
    "        except Exception as e: \n",
    "            course_rating_avarage = -1\n",
    "#             print(\"course_rating_avergae fail: \")#+ str(e))\n",
    "        \n",
    "        #course_price\n",
    "        course_price = -1\n",
    "        try:\n",
    "            course_price_elem = soup.find(\"div\",{\"data-purpose\":\"course-price-text\"})\n",
    "            course_price_text = course_price_elem.text\n",
    "            course_price = course_price_text.replace(\"Current priceâ‚ª\",\"\")\n",
    "#             print(course_price)\n",
    "        except Exception as e: \n",
    "            course_price = -1\n",
    "#             print(\"course_price fail: \")#+ str(e))\n",
    "  \n",
    "        #num_of_buyers_students\n",
    "        num_of_buyers_students = -1\n",
    "        try:\n",
    "            num_of_buyers_students_elem = soup.find('div', {\"class\" : 'enrollment'})\n",
    "            num_of_buyers_students_text = num_of_buyers_students_elem.string\n",
    "            num_of_buyers_students = num_of_buyers_students_text.replace(\" students\", \"\")\n",
    "#             print(num_of_buyers_students)\n",
    "        except Exception as e: \n",
    "            num_of_buyers_students = -1\n",
    "#             print(\"num_of_buyers_studens fail: \")#+ str(e))\n",
    "\n",
    "        #amount_of_instructor_studnets\n",
    "        amount_of_instructor_studnets = -1\n",
    "        try:\n",
    "            counter = 0\n",
    "            for d in soup.select('div.instructor--instructor__image-and-stats--1IqE7'):\n",
    "                for i in d.select('div.udlite-block-list-item-content'):  \n",
    "                    counter = counter + 1\n",
    "                    if(counter == 3):\n",
    "                        amount_of_instructor_studnets = i.text.replace(\" Students\", \"\")\n",
    "                        counter = 0\n",
    "#             print(amount_of_instructor_studnets)\n",
    "        except Exception as e: \n",
    "            amount_of_instructor_studnets = -1\n",
    "#             print(\"amount_of_instructor_students fail: \")#+ str(e))\n",
    "        \n",
    "        #num_articles\n",
    "        num_articles = -1\n",
    "        try:\n",
    "            num_articles_elem = soup.find(\"span\",{\"data-purpose\" : \"num-articles\"})\n",
    "            num_articles_text = num_articles_elem.text\n",
    "            num_articles = num_articles_text.replace(\" articles\",\"\").replace(\" article\", \"\")\n",
    "#             print(num_articles)\n",
    "        except Exception as e: \n",
    "            num_articles = -1\n",
    "#             print(\"num_articles fail: \")#+ str(e))\n",
    "        \n",
    "        #video_time_length\n",
    "        video_time_length = -1\n",
    "        try:\n",
    "            video_time_length_elem = soup.find(\"span\", {\"data-purpose\":\"video-content-length\"})\n",
    "            video_time_length_text = video_time_length_elem.text\n",
    "            video_time_length = video_time_length_text.replace(\" hours on-demand video\",\"\")\n",
    "#             print(video_time_length)\n",
    "        except Exception as e: \n",
    "            video_time_length = -1\n",
    "#             print(\"video_time_length fail: \")#+ str(e))\n",
    "        \n",
    "        #number_of_languages\n",
    "        number_of_languages = -1\n",
    "        try:\n",
    "            number_of_languages_elem = soup.find('button', attrs={'class':'udlite-btn udlite-btn-medium udlite-btn-link udlite-text-sm caption--more-button--3_cNb'})\n",
    "            if(number_of_languages_elem == None):\n",
    "                number_of_languages = 2\n",
    "            else:\n",
    "                number_of_languages = int(number_of_languages_elem.text.replace(\" more\", \"\")) + 2\n",
    "#             print(number_of_languages)\n",
    "        except Exception as e: \n",
    "            number_of_languages = -1\n",
    "#             print(\"number_of_languages fail: \")#+ str(e))\n",
    "    \n",
    "        #last_update\n",
    "        last_update = -1\n",
    "        try:\n",
    "            last_update_elem = soup.find('div', attrs={'class':'last-update-date'})\n",
    "            last_update = last_update_elem.text.replace(\"Last updated \",\"\")\n",
    "#             print(last_update)\n",
    "        except Exception as e: \n",
    "            last_update = -1\n",
    "#             print(\"last_update fail: \")#+ str(e))\n",
    "        \n",
    "        #instructor_rank\n",
    "        instructor_rank = -1\n",
    "        try:\n",
    "            for d in soup.select('div.instructor--instructor__image-and-stats--1IqE7'):\n",
    "                for i in d.select('div.udlite-block-list-item-content'):        \n",
    "                    instructor_rank = i.text.replace(\" Instructor Rating\",\"\")\n",
    "                    break\n",
    "#             print(instructor_rank)\n",
    "        except Exception as e: \n",
    "            instructor_rank = -1\n",
    "#             print(\"instructor_rank fail: \")#+ str(e))\n",
    "        \n",
    "        #amount_of_what_you_will_learn_count\n",
    "        amount_of_what_you_will_learn_count = -1\n",
    "        try:\n",
    "            amount_of_what_you_will_learn_ul = soup.find('ul', attrs={'class': 'unstyled-list udlite-block-list what-you-will-learn--objectives-list--2cWZN what-you-will-learn--objectives-list-two-column-layout--7vG__'})\n",
    "            amount_of_what_you_will_learn_count = 0\n",
    "            for li in amount_of_what_you_will_learn_ul.findAll('li'):\n",
    "                amount_of_what_you_will_learn_count = amount_of_what_you_will_learn_count + 1\n",
    "#             print(amount_of_what_you_will_learn_count)\n",
    "        except Exception as e: \n",
    "            amount_of_what_you_will_learn_count = -1\n",
    "#             print(\"amount_of_what_you_will_learn_count fail: \")#+ str(e))\n",
    "        \n",
    "        #amount_of_requirments_count\n",
    "        amount_of_requirments_count = -1\n",
    "        try:\n",
    "            amount_of_requirments_ul = soup.find('ul', attrs={'class': 'unstyled-list udlite-block-list'})\n",
    "            amount_of_requirments_count = 0\n",
    "            for li in amount_of_requirments_ul.findAll('li'):\n",
    "                amount_of_requirments_count = amount_of_requirments_count + 1\n",
    "#             print(amount_of_requirments_count)\n",
    "        except Exception as e: \n",
    "            amount_of_requirments_count = -1\n",
    "#             print(\"amount_of_requirments fail: \")#+ str(e))\n",
    "        \n",
    "        #amount_of_companies_support\n",
    "        amount_of_companies_support = -1\n",
    "        try:\n",
    "            amount_of_companies_support = 0\n",
    "            for d in soup.select('div.curated-for-ufb-notice--top-companies-logos--2_LsV'):\n",
    "                for i in d.select('img'):\n",
    "                    amount_of_companies_support = amount_of_companies_support + 1\n",
    "#             print(amount_of_companies_support)\n",
    "        except Exception as e: \n",
    "            amount_of_companies_support = -1\n",
    "#             print(\"amount_of_companies_support fail: \")#+ str(e))\n",
    "        \n",
    "        #course_rating_amount\n",
    "        course_rating_amount = -1\n",
    "        try:\n",
    "            course_rating_amount_elem =  soup.find('a',{\"class\":'styles--rating-wrapper--5a0Tr'})\n",
    "            children = course_rating_amount_elem.findChildren(\"span\" , recursive=False)\n",
    "            course_rating_amount = children[-1].text.replace(\" ratings)\",\"\")\n",
    "            course_rating_amount = course_rating_amount.replace(\"(\",\"\")\n",
    "#             print(course_rating_amount)\n",
    "        except Exception as e: \n",
    "            course_rating_amount = -1\n",
    "#             print(\"course_rating_amount fail: \")#+ str(e))\n",
    "\n",
    "        \n",
    "        data = [[best_seller, course_rating_avarage, course_price, num_of_buyers_students, amount_of_instructor_studnets, num_articles, video_time_length, number_of_languages, last_update, instructor_rank, amount_of_what_you_will_learn_count, amount_of_requirments_count, amount_of_companies_support, course_rating_amount]]\n",
    "        columns = [\"best_seller\", \"course_rating_avarage\", \"course_price\", \"num_of_buyers_students\", \"amount_of_instructor_studnets\", \"num_articles\", \"video_time_length\", \"number_of_languages\", \"last_update\", \"instructor_rank\", \"amount_of_what_you_will_learn_count\", \"amount_of_requirments_count\", \"amount_of_companies_support\", \"course_rating_amount\"]\n",
    "        df = pd.DataFrame(data, columns = columns)\n",
    "        \n",
    "        file_name = 'UDEMY_DATA.csv'\n",
    "        if not os.path.isfile(file_name):\n",
    "            df.to_csv(file_name, header=columns ,index=False)\n",
    "        else:\n",
    "            df.to_csv(file_name, mode='a', header=False, index=False)\n",
    "        \n",
    "        forward_url()\n",
    "    except Exception as e: \n",
    "        print(\"Failed in run_web_driver: \")#+ str(e))\n",
    "        forward_url()\n",
    "\n",
    "forward_url()\n",
    "run_web_driver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5319507",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
